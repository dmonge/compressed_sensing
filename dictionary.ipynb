{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d17fb18-cf27-4c37-b5ab-ccc342d39a07",
   "metadata": {},
   "source": [
    "# Compressed sensing on images\n",
    "\n",
    "This notebook intends to illustrate the application of compressed sensing to images.\n",
    "\n",
    "In particular, given an undersampled image $y$ (on the left), the objective is to reconstruct the original image $x$ (on the right):\n",
    "\n",
    "![](extra/compressed_sensing.png)\n",
    "\n",
    "This notebook applies compressed sensing as in [compressed_sensing.ipynb](compressed_sensing.ipynb) but, in this case, to a 2D problem.\n",
    "\n",
    "Another difference is that in this notebook the basis matrix $\\Psi$ is defined as a collection of images defined as a column vectors instead of the Discrete Cosine Transform matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bfab32-5c24-4965-92ef-1532dccf6104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import ma\n",
    "from scipy.sparse import dok_array\n",
    "import torch\n",
    "from icecream import ic\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Compose\n",
    "from torchvision.transforms import Resize\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.transforms import Grayscale\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from optimize import cosamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d87adb-3d6a-48cd-8b08-b48784cbf624",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_LABELS = (9, 1, 3)\n",
    "TARGET_LABEL = DATA_LABELS[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412b952a-ff74-4885-a345-b930023bfaa8",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdd287a-96e0-408e-9a02-4540d5522e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "img_size = 128\n",
    "n_channels = 1\n",
    "transform = Compose([Resize(img_size), ToTensor(), Grayscale()])\n",
    "train_dataset = MNIST('data', train=True, transform=transform, download=True)\n",
    "test_dataset = MNIST('data', train=False, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dac901a-db69-42b3-82de-42564a3f648c",
   "metadata": {},
   "source": [
    "## Problem definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce1e855-52d0-43f8-b2f8-cad01a331e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = img_size * img_size * n_channels\n",
    "p = n\n",
    "i = 0\n",
    "signal_dim = n\n",
    "undersampled_dim = int(n * 0.1)  # measure 10%\n",
    "dictionary_size = 2048"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590c5e95-d33c-475b-bf23-3cf8b220c622",
   "metadata": {},
   "source": [
    "## Signal\n",
    "$x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bb523a-9fd3-47d7-b768-977943ca7684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample image\n",
    "i = 0\n",
    "while True:\n",
    "    test_image, target = test_dataset[i]\n",
    "    if target == TARGET_LABEL:\n",
    "        break\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a329f71-0fe5-4a06-8182-a8385ad4a130",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_image.permute(1, 2, 0))\n",
    "plt.title('original image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9935e81f-6d23-429d-abcc-962077c68d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test_image.view(-1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfea88e-c2b6-45af-b90a-1635b9ec9971",
   "metadata": {},
   "source": [
    "## Sample matrix\n",
    "$C$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f4c72c-c6d1-4ac9-94b3-031538ac229c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_matrix(undersampled_dim, signal_dim):\n",
    "    return np.eye(signal_dim)[np.random.randint(signal_dim, size=undersampled_dim)]\n",
    "\n",
    "C = sample_matrix(undersampled_dim, signal_dim)\n",
    "ic(np.count_nonzero(C))\n",
    "plt.imshow(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4705918-5a83-4cf8-a6cc-3b83c201e300",
   "metadata": {},
   "source": [
    "## Undersampled signal\n",
    "$y = C x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9229b6c-f7ad-4213-86fd-4e870c7c3945",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = C @ x\n",
    "_coord = C @ np.arange(n)\n",
    "plt.plot(x, alpha=0.2, label='original signal')\n",
    "plt.plot(_coord, y, '.', c='orange', label='undersampled signal')\n",
    "plt.xlabel('pixels')\n",
    "plt.ylabel('values')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4651821-1add-46d7-80f0-99c6a9f5ff93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling mask\n",
    "ii, jj = np.meshgrid(np.arange(img_size), np.arange(img_size), indexing='ij')\n",
    "ii = C @ ii.flatten()\n",
    "jj = C @ jj.flatten()\n",
    "mask = dok_array((img_size, img_size), dtype=bool)\n",
    "mask[ii, jj] = True\n",
    "\n",
    "# plot\n",
    "subsampled_image = ma.masked_array(\n",
    "    x.reshape(img_size, img_size),\n",
    "    mask=~mask.todense()\n",
    ")\n",
    "plt.imshow(subsampled_image)\n",
    "plt.title('undersampled image')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c57d21-b656-4930-a350-97a6a589edf9",
   "metadata": {},
   "source": [
    "## The problem\n",
    "As mentioned at the beggining, given an undersampled image $y$ (on the left), the objective is to reconstruct the original image $x$ (on the right):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2b790f-9275-43c2-b133-5055a999d25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, (ax1, ax2) = plt.subplots(ncols=2)\n",
    "\n",
    "ax1.imshow(subsampled_image)\n",
    "ax1.set_title('undersampled image $y$')\n",
    "ax2.imshow(test_image.permute(1, 2, 0))\n",
    "ax2.set_title('original image $x$')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38668ee3-342e-492f-b211-abc67e010b5f",
   "metadata": {},
   "source": [
    "## Dictionary\n",
    "$\\Psi$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df7c638-0305-4cef-ba6e-50138c16dd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  dictionary images\n",
    "dictionary_images = []\n",
    "indices = []\n",
    "i = 0\n",
    "while len(dictionary_images) < dictionary_size:\n",
    "    image, target = train_dataset[i]\n",
    "    if target in DATA_LABELS:\n",
    "        dictionary_images.append(image)\n",
    "        indices.append(i)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277d62fa-5235-46b9-8363-cf2deca67d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview\n",
    "grid = make_grid(dictionary_images[:100], nrow=10)\n",
    "ic(grid.shape)\n",
    "plt.imshow(grid[0], cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14bed8d-488c-43dc-b9c5-bf253a8504b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Psi = torch.stack(dictionary_images, dim=-1).view(n_channels * img_size * img_size, -1).numpy()\n",
    "ic(Psi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd65c9e9-aa08-48ab-bdd1-6e315bdbc71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Psi)\n",
    "plt.xlabel('images')\n",
    "plt.ylabel('pixels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c62a64-0bed-4d60-a566-61d69dd09326",
   "metadata": {},
   "source": [
    "## Theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d16e6e-0be3-496f-949a-cc5d38104cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Theta = C @ Psi\n",
    "plt.imshow(Theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfda119-52ca-4a5e-a18c-09a8e98fba12",
   "metadata": {},
   "source": [
    "## Find sparse representation $s$ of $y$\n",
    "\n",
    "Find $s$ by solving:\n",
    "\n",
    "$min ||s||_1$ s.t. $y = \\Theta s$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f255cce8-ad87-4038-b6de-b4b9687e775b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize\n",
    "sparsity = 5  # number of sparse elements in solution\n",
    "s = cosamp(Theta, y, sparsity, max_iter=10000)\n",
    "ic(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88d43cf-cdcb-42c2-9ee4-238eb3b35ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols=2, nrows=1)\n",
    "\n",
    "ax1.plot(s, 'red', alpha=.5)\n",
    "ax1.plot(s, '.')\n",
    "ax1.set_title('s')\n",
    "ax2.hist(s)\n",
    "ax2.set_title('histogram of s')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e1de56-9b69-468c-9dfb-ce95e2cd4ebd",
   "metadata": {},
   "source": [
    "### Check $s$ quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee84dc7-39e3-4bc2-824d-8e4a660a6e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols=2)\n",
    "ax1.plot(y, label='$y$')\n",
    "ax1.plot(Theta @ s, '.', label='$\\Theta s$')\n",
    "ax1.set_title('$s$ vs. $\\Theta s$')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(Theta @ s - y)\n",
    "ax2.set_title('difference')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7513f4ed-82ee-4a9c-980a-1ffdf32f8658",
   "metadata": {},
   "source": [
    "## Recover $x$\n",
    "\n",
    "This is done by computing $x = \\Psi s$ using the obtained sparse vector $s$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e834eb5c-fa54-4811-8564-6d4edd8abee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_r = Psi @ s\n",
    "_coord = C @ np.arange(n)\n",
    "plt.plot(x, alpha=0.5, label='original signal')\n",
    "plt.plot(_coord, y, '.', c='orange', label='undersampled signal')\n",
    "plt.plot(x_r, c='green', label='recovered signal')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08e3a8e-4263-48ff-9406-cda42f43fbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "_x = x.reshape(img_size, img_size)\n",
    "_x_r = x_r.reshape(img_size, img_size)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2)\n",
    "\n",
    "img = ax1.imshow(_x) #, cmap='Grays_r')\n",
    "ax1.set_title('y')\n",
    "fig.colorbar(img)\n",
    "\n",
    "img = ax2.imshow(_x_r)#, cmap='Grays_r')\n",
    "ax2.set_title('reconstructed y')\n",
    "fig.colorbar(img)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e3c210-a244-4901-805c-9262f63e64f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _idx = torch.topk(torch.tensor(np.abs(s)), sparsity)\n",
    "ic(_idx)\n",
    "grid = make_grid([torch.tensor(Psi[:, i].reshape(img_size, img_size)).unsqueeze(0) for i in _idx], nrow=sparsity // 2)\n",
    "ic(grid.shape)\n",
    "# plt.imshow(grid.permute(1, 2, 0), cmap='viridis')\n",
    "plt.imshow(grid[0], cmap='viridis')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
